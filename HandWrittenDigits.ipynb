{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T14:00:39.803415Z",
     "start_time": "2024-07-22T14:00:39.782750Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2  # OpenCV for image resizing\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator \n",
    "from tensorflow.keras.layers import BatchNormalization"
   ],
   "id": "d651ef1d6136ed4e",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T14:02:32.263348Z",
     "start_time": "2024-07-22T14:00:40.070535Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Update these paths to the correct locations of your .mat files\n",
    "train_data_path = r'C:\\Users\\Kiran\\Downloads\\handwritten digits\\SVHN\\train_32x32.mat'\n",
    "test_data_path = r'C:\\Users\\Kiran\\Downloads\\handwritten digits\\SVHN\\test_32x32.mat'\n",
    "\n",
    "# Load SVHN dataset\n",
    "train_data = loadmat(train_data_path)\n",
    "test_data = loadmat(test_data_path)\n",
    "\n",
    "X_train_svhn = np.array(train_data['X'])\n",
    "Y_train_svhn = np.array(train_data['y'])\n",
    "X_test_svhn = np.array(test_data['X'])\n",
    "Y_test_svhn = np.array(test_data['y'])\n",
    "\n",
    "# Transpose the SVHN data to match the required shape (num_samples, height, width, channels)\n",
    "X_train_svhn = np.transpose(X_train_svhn, (3, 0, 1, 2))\n",
    "X_test_svhn = np.transpose(X_test_svhn, (3, 0, 1, 2))\n",
    "\n",
    "# Replace label 10 with 0 to match standard digit classification (0-9)\n",
    "Y_train_svhn[Y_train_svhn == 10] = 0\n",
    "Y_test_svhn[Y_test_svhn == 10] = 0\n",
    "\n",
    "# Load MNIST dataset\n",
    "(X_train_mnist, Y_train_mnist), (X_test_mnist, Y_test_mnist) = mnist.load_data()\n",
    "\n",
    "# Resize MNIST images to 32x32\n",
    "X_train_mnist_resized = np.array([cv2.resize(img, (32, 32)) for img in X_train_mnist])\n",
    "X_test_mnist_resized = np.array([cv2.resize(img, (32, 32)) for img in X_test_mnist])\n",
    "\n",
    "# Expand dimensions to convert to RGB (3 channels)\n",
    "X_train_mnist_resized = np.stack((X_train_mnist_resized,) * 3, axis=-1)\n",
    "X_test_mnist_resized = np.stack((X_test_mnist_resized,) * 3, axis=-1)\n",
    "\n",
    "# Ensure MNIST labels are in the same format\n",
    "Y_train_mnist = Y_train_mnist.reshape(-1, 1)\n",
    "Y_test_mnist = Y_test_mnist.reshape(-1, 1)\n",
    "\n",
    "# Combine SVHN and MNIST datasets\n",
    "X_train_combined = np.vstack((X_train_svhn, X_train_mnist_resized))\n",
    "Y_train_combined = np.vstack((Y_train_svhn, Y_train_mnist))\n",
    "\n",
    "X_test_combined = np.vstack((X_test_svhn, X_test_mnist_resized))\n",
    "Y_test_combined = np.vstack((Y_test_svhn, Y_test_mnist))\n",
    "\n",
    "# Normalize the combined dataset\n",
    "X_train_combined = X_train_combined.astype('float32') / 255.0\n",
    "X_test_combined = X_test_combined.astype('float32') / 255.0\n",
    "\n",
    "print(X_train_combined.shape, Y_train_combined.shape)\n",
    "print(X_test_combined.shape, Y_test_combined.shape)\n",
    "\n",
    "print(X_train_combined.ndim)\n",
    "print(Y_train_combined.ndim)\n",
    "\n",
    "aug_X = np.empty_like(X_train_combined)\n",
    "aug_Y = np.empty_like(Y_train_combined)\n",
    "\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    \n",
    "    channel_shift_range=50.0,  # Randomly shift color channels within the range [-50, 50]\n",
    "    brightness_range=[0.5, 1.0],  # Adjust brightness to be between 50% and 100%\n",
    "    horizontal_flip=True\n",
    "    \n",
    ")\n",
    "num_samples = X_train_combined.shape[0]\n",
    "data_gen = datagen.flow(X_train_combined, Y_train_combined,batch_size=32)\n",
    "for i in range (num_samples // 32):\n",
    "    X_batch,Y_batch = next(data_gen)\n",
    "    aug_X[i*32:(i+1)*32] = X_batch\n",
    "    aug_Y[i*32:(i+1)*32] = Y_batch\n",
    "X_train_combined = np.vstack((X_train_combined,aug_X))\n",
    "Y_train_combined = np.vstack((Y_train_combined,aug_Y))"
   ],
   "id": "29ecb87c4b7d1822",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133257, 32, 32, 3) (133257, 1)\n",
      "(36032, 32, 32, 3) (36032, 1)\n",
      "4\n",
      "2\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T17:19:02.488145Z",
     "start_time": "2024-07-22T17:17:08.618184Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# def contrast_adjustment(img):\n",
    "#     alpha = 0.5  # Contrast control\n",
    "#     img = img * 255.0  # Convert to 0-255 range\n",
    "#     mean = np.mean(img, axis=(0, 1, 2), keepdims=True)\n",
    "#     img = alpha * (img - mean) + mean\n",
    "#     img = np.clip(img, 0, 255)\n",
    "#     img /= 255.0  # Normalize back to 0-1 range\n",
    "#     return img\n",
    "# \n",
    "# # Apply the custom function using ImageDataGenerator\n",
    "# datagen1 = ImageDataGenerator(\n",
    "#     preprocessing_function=contrast_adjustment,\n",
    "#     brightness_range=[0.5, 1.0],  # Adjust brightness to be between 50% and 100%\n",
    "#     horizontal_flip=True\n",
    "# )\n",
    "# \n",
    "# data_gen1 = datagen1.flow(X_train_combined,Y_train_combined,batch_size=32)\n",
    "# for i in range (num_samples // 32):\n",
    "#     X_batch,Y_batch = next(data_gen1)\n",
    "#     aug_X[i*32:(i+1)*32] = X_batch\n",
    "#     aug_Y[i*32:(i+1)*32] = Y_batch\n",
    "# X_train_combined = np.vstack((X_train_combined,aug_X))\n",
    "# Y_train_combined = np.vstack((Y_train_combined,aug_Y))"
   ],
   "id": "d7e3d6bdf23e3d52",
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 4.58 GiB for an array with shape (399771, 32, 32, 3) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mMemoryError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[22], line 22\u001B[0m\n\u001B[0;32m     20\u001B[0m     aug_X[i\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m32\u001B[39m:(i\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m)\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m32\u001B[39m] \u001B[38;5;241m=\u001B[39m X_batch\n\u001B[0;32m     21\u001B[0m     aug_Y[i\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m32\u001B[39m:(i\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m)\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m32\u001B[39m] \u001B[38;5;241m=\u001B[39m Y_batch\n\u001B[1;32m---> 22\u001B[0m X_train_combined \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvstack\u001B[49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train_combined\u001B[49m\u001B[43m,\u001B[49m\u001B[43maug_X\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     23\u001B[0m Y_train_combined \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mvstack((Y_train_combined,aug_Y))\n",
      "File \u001B[1;32m~\\PycharmProjects\\pyhonintern_task1\\.venv\\Lib\\site-packages\\numpy\\core\\shape_base.py:289\u001B[0m, in \u001B[0;36mvstack\u001B[1;34m(tup, dtype, casting)\u001B[0m\n\u001B[0;32m    287\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(arrs, \u001B[38;5;28mlist\u001B[39m):\n\u001B[0;32m    288\u001B[0m     arrs \u001B[38;5;241m=\u001B[39m [arrs]\n\u001B[1;32m--> 289\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_nx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconcatenate\u001B[49m\u001B[43m(\u001B[49m\u001B[43marrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcasting\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcasting\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mMemoryError\u001B[0m: Unable to allocate 4.58 GiB for an array with shape (399771, 32, 32, 3) and data type float32"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T14:03:41.318786Z",
     "start_time": "2024-07-22T14:03:41.314310Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, kernel_size=(3, 3), padding='same',activation = \"relu\", input_shape=(32, 32, 3)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    Conv2D(64, kernel_size=(3, 3),activation = \"relu\" ,padding='same'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    Conv2D(128, kernel_size=(3, 3),activation = \"relu\" ,padding='same'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    Conv2D(256, kernel_size=(3, 3), activation = \"relu\",padding='same'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])"
   ],
   "id": "497ba6c854ff16e5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T14:03:41.334164Z",
     "start_time": "2024-07-22T14:03:41.330091Z"
    }
   },
   "cell_type": "code",
   "source": "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])",
   "id": "afb7c30a89f10fdf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T14:03:41.336174Z",
     "start_time": "2024-07-22T14:03:41.336174Z"
    }
   },
   "cell_type": "code",
   "source": "model.fit(X_train_combined, Y_train_combined, epochs=2, validation_data=(X_test_combined, Y_test_combined))",
   "id": "f56b8ef9a9d411f2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T14:03:41.345308Z",
     "start_time": "2024-07-22T14:03:41.343496Z"
    }
   },
   "cell_type": "code",
   "source": [
    "loss, accuracy = model.evaluate(X_test_combined, Y_test_combined)\n",
    "print(f\"The accuracy is: {accuracy}\")\n",
    "print(f\"The loss is: {loss}\")\n",
    "\n",
    "# Prediction on new images\n",
    "path_dir = r\"C:\\Users\\Kiran\\Downloads\\handwritten digits\\handwritten\"\n",
    "for i in os.listdir(path_dir):\n",
    "    img_path = os.path.join(path_dir, i)\n",
    "    img = image.load_img(img_path, color_mode='rgb', target_size=(32, 32,3))\n",
    "    plt.imshow(img, cmap='gray')\n",
    "\n",
    "    X = image.img_to_array(img)\n",
    "    X = np.expand_dims(X, axis=0)  # Expand dims to create a batch of size 1\n",
    "    logits = model.predict(X)\n",
    "    print(logits)\n",
    "    predicted_class = np.argmax(logits)\n",
    "    print(f\"Predicted class for {i}: {predicted_class}\")\n",
    "    plt.title(predicted_class)\n",
    "    plt.show()\n",
    "    time.sleep(2)\n",
    "    plt.close()"
   ],
   "id": "bac022c48549b66d",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
